{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85711ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b046d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/olistbr/brazilian-ecommerce?dataset_version_number=2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42.6M/42.6M [00:05<00:00, 7.52MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\harsh\\.cache\\kagglehub\\datasets\\olistbr\\brazilian-ecommerce\\versions\\2\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"olistbr/brazilian-ecommerce\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4809cecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kagglehub\n",
      "  Downloading kagglehub-0.3.13-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\harsh\\appdata\\roaming\\python\\python313\\site-packages (from kagglehub) (25.0)\n",
      "Collecting pyyaml (from kagglehub)\n",
      "  Downloading pyyaml-6.0.3-cp313-cp313-win_amd64.whl.metadata (2.4 kB)\n",
      "Collecting requests (from kagglehub)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting tqdm (from kagglehub)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests->kagglehub)\n",
      "  Using cached charset_normalizer-3.4.3-cp313-cp313-win_amd64.whl.metadata (37 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->kagglehub)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->kagglehub)\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->kagglehub)\n",
      "  Downloading certifi-2025.10.5-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\harsh\\appdata\\roaming\\python\\python313\\site-packages (from tqdm->kagglehub) (0.4.6)\n",
      "Downloading kagglehub-0.3.13-py3-none-any.whl (68 kB)\n",
      "Downloading pyyaml-6.0.3-cp313-cp313-win_amd64.whl (154 kB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Using cached charset_normalizer-3.4.3-cp313-cp313-win_amd64.whl (107 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Downloading certifi-2025.10.5-py3-none-any.whl (163 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: urllib3, tqdm, pyyaml, idna, charset_normalizer, certifi, requests, kagglehub\n",
      "\n",
      "   ---------------------------------------- 0/8 [urllib3]\n",
      "   ---------------------------------------- 0/8 [urllib3]\n",
      "   ---------------------------------------- 0/8 [urllib3]\n",
      "   ---------------------------------------- 0/8 [urllib3]\n",
      "   ----- ---------------------------------- 1/8 [tqdm]\n",
      "   ----- ---------------------------------- 1/8 [tqdm]\n",
      "   ----- ---------------------------------- 1/8 [tqdm]\n",
      "   ----- ---------------------------------- 1/8 [tqdm]\n",
      "   ----- ---------------------------------- 1/8 [tqdm]\n",
      "   ---------- ----------------------------- 2/8 [pyyaml]\n",
      "   ---------- ----------------------------- 2/8 [pyyaml]\n",
      "   --------------- ------------------------ 3/8 [idna]\n",
      "   -------------------- ------------------- 4/8 [charset_normalizer]\n",
      "   -------------------- ------------------- 4/8 [charset_normalizer]\n",
      "   -------------------- ------------------- 4/8 [charset_normalizer]\n",
      "   ------------------------------ --------- 6/8 [requests]\n",
      "   ------------------------------ --------- 6/8 [requests]\n",
      "   ------------------------------ --------- 6/8 [requests]\n",
      "   ----------------------------------- ---- 7/8 [kagglehub]\n",
      "   ----------------------------------- ---- 7/8 [kagglehub]\n",
      "   ----------------------------------- ---- 7/8 [kagglehub]\n",
      "   ---------------------------------------- 8/8 [kagglehub]\n",
      "\n",
      "Successfully installed certifi-2025.10.5 charset_normalizer-3.4.3 idna-3.10 kagglehub-0.3.13 pyyaml-6.0.3 requests-2.32.5 tqdm-4.67.1 urllib3-2.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "284e8247",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\AppData\\Local\\Temp\\ipykernel_24672\\1954212225.py:13: DeprecationWarning: Call to deprecated function get_server_info. Reason: \n",
      "    The property counterpart 'server_info' should be used instead.\n",
      "\n",
      "  db_Info = connection.get_server_info()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to MySQL Server version  8.0.36-28\n",
      "You're connected to database:  ('OlistPorject_flatpurple',)\n",
      "MySQL connection is closed\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "\n",
    "hostname = \"s8jzuo.h.filess.io\"\n",
    "database = \"OlistPorject_flatpurple\"\n",
    "port = \"61032\"\n",
    "username = \"OlistPorject_flatpurple\"\n",
    "password = \"c84d78e7baa4721f924e30ba135f4f52c15a1da0\"\n",
    "\n",
    "try:\n",
    "    connection = mysql.connector.connect(host=hostname, database=database, user=username, password=password, port=port)\n",
    "    if connection.is_connected():\n",
    "        db_Info = connection.get_server_info()\n",
    "        print(\"Connected to MySQL Server version \", db_Info)\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(\"select database();\")\n",
    "        record = cursor.fetchone()\n",
    "        print(\"You're connected to database: \", record)\n",
    "\n",
    "except Error as e:\n",
    "    print(\"Error while connecting to MySQL\", e)\n",
    "finally:\n",
    "    if connection.is_connected():\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "        print(\"MySQL connection is closed\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5cf37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "\n",
    "# Connection details\n",
    "hostname = \"s8jzuo.h.filess.io\"\n",
    "database = \"OlistPorject_flatpurple\"\n",
    "port = \"61032\"\n",
    "username = \"OlistPorject_flatpurple\"\n",
    "password = \"topsecret\"\n",
    "\n",
    "# CSV file path\n",
    "csv_file_path = \"olist_order_payments_dataset.csv\"\n",
    "\n",
    "# Table name where the data will be uploaded\n",
    "table_name = \"olist_order_payments\"\n",
    "\n",
    "try:\n",
    "    # Step 1: Establish a connection to MySQL server\n",
    "    connection = mysql.connector.connect(\n",
    "        host=hostname,\n",
    "        database=database,\n",
    "        user=username,\n",
    "        password=password,\n",
    "        port=port\n",
    "    )\n",
    "    if connection.is_connected():\n",
    "        print(\"Connected to MySQL Server successfully!\")\n",
    "\n",
    "        # Step 2: Create a cursor to execute SQL queries\n",
    "        cursor = connection.cursor()\n",
    "\n",
    "        # Step 3: Drop table if it already exists (for clean insertion)\n",
    "        cursor.execute(f\"DROP TABLE IF EXISTS {table_name};\")\n",
    "        print(f\"Table `{table_name}` dropped if it existed.\")\n",
    "\n",
    "        # Step 4: Create a table structure to match CSV file\n",
    "        create_table_query = f\"\"\"\n",
    "        CREATE TABLE {table_name} (\n",
    "            order_id VARCHAR(50),\n",
    "            payment_sequential INT,\n",
    "            payment_type VARCHAR(20),\n",
    "            payment_installments INT,\n",
    "            payment_value FLOAT\n",
    "        );\n",
    "        \"\"\"\n",
    "        cursor.execute(create_table_query)\n",
    "        print(f\"Table `{table_name}` created successfully!\")\n",
    "\n",
    "        # Step 5: Load the CSV data into pandas DataFrame\n",
    "        data = pd.read_csv(csv_file_path)\n",
    "        print(\"CSV data loaded into pandas DataFrame.\")\n",
    "\n",
    "        # Step 6: Insert data in batches of 500 records\n",
    "        batch_size = 500  # Define the batch size\n",
    "        total_records = len(data)  # Get total records in the DataFrame\n",
    "\n",
    "        print(f\"Starting data insertion into `{table_name}` in batches of {batch_size} records.\")\n",
    "        for start in range(0, total_records, batch_size):\n",
    "            end = start + batch_size\n",
    "            batch = data.iloc[start:end]  # Get the current batch of records\n",
    "\n",
    "            # Convert batch to list of tuples for MySQL insertion\n",
    "            batch_records = [\n",
    "                tuple(row) for row in batch.itertuples(index=False, name=None)\n",
    "            ]\n",
    "\n",
    "            # Prepare the INSERT query\n",
    "            insert_query = f\"\"\"\n",
    "            INSERT INTO {table_name}\n",
    "            (order_id, payment_sequential, payment_type, payment_installments, payment_value)\n",
    "            VALUES (%s, %s, %s, %s, %s);\n",
    "            \"\"\"\n",
    "\n",
    "            # Execute the insertion query for the batch\n",
    "            cursor.executemany(insert_query, batch_records)\n",
    "            connection.commit()  # Commit after each batch\n",
    "            print(f\"Inserted records {start + 1} to {min(end, total_records)} successfully.\")\n",
    "\n",
    "        print(f\"All {total_records} records inserted successfully into `{table_name}`.\")\n",
    "\n",
    "except Error as e:\n",
    "    # Step 7: Handle any errors\n",
    "    print(\"Error while connecting to MySQL or inserting data:\", e)\n",
    "\n",
    "finally:\n",
    "    # Step 8: Close the cursor and connection\n",
    "    if connection.is_connected():\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "        print(\"MySQL connection is closed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
